{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/jutsus.jsonl\"\n",
    "df = pd.read_json(data_path, lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_jutsu(jutsu):\n",
    "    if \"Genjutsu\" in jutsu:\n",
    "        return \"Genjutsu\"\n",
    "    if \"Ninjutsu\" in jutsu:\n",
    "        return \"Ninjutsu\"\n",
    "    if \"Taijutsu\" in jutsu:\n",
    "        return \"Taijutsu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['jutsu_type_simplified'] = df['jutsu_type'].apply(simplify_jutsu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['jutsu_type_simplified'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['jutsu_name'] + \". \" + df['jutsu_description']\n",
    "df['jutsus'] = df['jutsu_type_simplified']\n",
    "df = df[['text', 'jutsus']]\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "class Cleaner():\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    \n",
    "    def put_line_breaks(self, text):\n",
    "        return text.replace(\"<\\p>\", \"<\\p>\\n\")\n",
    "    \n",
    "    def remove_html_tags(self, text):\n",
    "        clean_text = BeautifulSoup(text, \"lxml\").text\n",
    "        return clean_text\n",
    "\n",
    "    def clean(self, text):\n",
    "        text = self.put_line_breaks(text)\n",
    "        text = self.remove_html_tags(text)\n",
    "        text = text.strip()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column_name = 'text'\n",
    "label_column_name = \"jutsus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Text\n",
    "cleaner = Cleaner()\n",
    "df['text_cleaned'] = df[text_column_name].apply(cleaner.clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Labels \n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df[label_column_name].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {index:label_name for index, label_name in enumerate(le.__dict__['classes_'].tolist())}\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = le.transform(df[label_column_name].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "df_train, df_test = train_test_split(df, \n",
    "                                     test_size=test_size, \n",
    "                                     stratify=df['label'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['jutsus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert/distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(tokenizer,examples):\n",
    "    return tokenizer(examples['text_cleaned'],truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conver Pandas to a hugging face dataset\n",
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "test_dataset = Dataset.from_pandas(df_test)\n",
    "\n",
    "# tokenize the dataset\n",
    "tokenized_train = train_dataset.map(lambda examples: preprocess_function(tokenizer, examples),\n",
    "                                    batched=True)\n",
    "tokenized_test = test_dataset.map(lambda examples: preprocess_function(tokenizer, examples),\n",
    "                                    batched=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
