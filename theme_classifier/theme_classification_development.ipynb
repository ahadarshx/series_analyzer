{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from nltk import sent_tokenize\n",
    "import nltk\n",
    "import torch\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-large-mnli\"\n",
    "device = 0 if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(device):\n",
    "    theme_classifier = pipeline(\n",
    "        \"zero-shot-classification\",\n",
    "        model=model_name,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    return theme_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_classifier = load_model(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_list = [\"friendship\",\"hope\",\"sacrifice\",\"battle\",\"self development\",\"betrayal\",\"love\",\"dialogue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_classifier(\n",
    "    \"I gave him a right hook then a left jab\",\n",
    "    theme_list,\n",
    "    multi_label=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('../data/Subtitles/*.ass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(files[0],'r') as file:\n",
    "    lines = file.readlines()\n",
    "    lines = lines[27:]\n",
    "    lines =  [ \",\".join(line.split(',')[9:])  for line in lines ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [ line.replace('\\\\N',' ') for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(lines[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(files[0].split('-')[-1].split('.')[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "def load_subtitles_dataset(dataset_path):\n",
    "    # Find all .ass subtitle files in the dataset_path\n",
    "    subtitles_paths = glob(os.path.join(dataset_path, '*.ass'))\n",
    "\n",
    "    scripts = []\n",
    "    episode_num = []\n",
    "\n",
    "    for path in subtitles_paths:\n",
    "        try:\n",
    "            # Read lines with UTF-8 encoding, handling errors gracefully\n",
    "            with open(path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "                lines = file.readlines()\n",
    "\n",
    "            # Skip the first 27 lines (assuming metadata) and extract the dialogue part\n",
    "            lines = lines[27:]\n",
    "            lines = [\",\".join(line.split(',')[9:]) for line in lines]\n",
    "\n",
    "            # Replace '\\N' (newlines in ASS subtitles) with a space\n",
    "            lines = [line.replace('\\\\N', ' ') for line in lines]\n",
    "\n",
    "            # Join the lines to form the full script for the episode\n",
    "            script = \" \".join(lines)\n",
    "\n",
    "            # Extract the episode number from the filename\n",
    "            episode = int(path.split('-')[-1].split('.')[0].strip())\n",
    "\n",
    "            # Append script and episode number to the lists\n",
    "            scripts.append(script)\n",
    "            episode_num.append(episode)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {path}: {e}\")\n",
    "\n",
    "    # Create a DataFrame with the episode number and script\n",
    "    df = pd.DataFrame.from_dict({\"episode\": episode_num, \"script\": scripts})\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../data/Subtitles\"\n",
    "df = load_subtitles_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = df.iloc[0]['script']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "script_sentences = sent_tokenize(script)\n",
    "print(script_sentences[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Sentence\n",
    "sentence_batch_size=20\n",
    "script_batches = []\n",
    "for index in range(0,len(script_sentences),sentence_batch_size):\n",
    "    sent = \" \".join(script_sentences[index:index+sentence_batch_size])\n",
    "    script_batches.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_batches[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_output = theme_classifier(\n",
    "    script_batches[:2],\n",
    "    theme_list,\n",
    "    multi_label=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrangle Ouput\n",
    "# battle: [0.51489498, 0.2156498]\n",
    "themes = {}\n",
    "for output in theme_output:\n",
    "    for label,score in zip(output['labels'],output['scores']):\n",
    "        if label not in themes:\n",
    "            themes[label] = []\n",
    "        themes[label].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "themes = {key: np.mean(np.array(value)) for key,value in themes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_themes_inference(script):\n",
    "    script_sentences = sent_tokenize(script)\n",
    "\n",
    "    # Batch Sentence\n",
    "    sentence_batch_size=20\n",
    "    script_batches = []\n",
    "    for index in range(0,len(script_sentences),sentence_batch_size):\n",
    "        sent = \" \".join(script_sentences[index:index+sentence_batch_size])\n",
    "        script_batches.append(sent)\n",
    "    \n",
    "    # Run Model\n",
    "    theme_output = theme_classifier(\n",
    "        script_batches[:2],\n",
    "        theme_list,\n",
    "        multi_label=True\n",
    "    )\n",
    "\n",
    "    # Wrangle Output \n",
    "    themes = {}\n",
    "    for output in theme_output:\n",
    "        for label,score in zip(output['labels'],output['scores']):\n",
    "            if label not in themes:\n",
    "                themes[label] = []\n",
    "            themes[label].append(score)\n",
    "\n",
    "    themes = {key: np.mean(np.array(value)) for key,value in themes.items()}\n",
    "\n",
    "    return themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_themes = df['script'].apply(get_themes_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_df = pd.DataFrame(output_themes.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[theme_df.columns] = theme_df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('dialogue',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_output = df.drop(['episode','script'],axis=1).sum().reset_index()\n",
    "theme_output.columns = ['theme','score']\n",
    "theme_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = theme_output ,x=\"theme\",y=\"score\" )\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
